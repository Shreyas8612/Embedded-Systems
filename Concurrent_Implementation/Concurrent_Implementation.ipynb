{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "09408495-8c55-44b9-bed3-7975f634bab8",
      "metadata": {
        "id": "09408495-8c55-44b9-bed3-7975f634bab8"
      },
      "source": [
        "# EEE3027 Lab 5 - Multithreaded Machine Learning (ML) Processes\n",
        "\n",
        "In last week's lab session, we showcased the design of the IoT 'Sensor - Processor' Co-Simulation Example and introduced the concepts of concurrency through the use of mutexes and semaphores via multithreading.\n",
        "\n",
        "For this week's lab session, we extend this example by introducing a singular 'Sensor' which we will call 'DataLoader' and two 'Processors' which we will call 'TrainerReader' and 'InfererReader' respectively.\n",
        "\n",
        "Although this example is relatively simple compared to how the data source is actually managed in the coursework example, these concepts, however, can still in principle be applied to sufficiently (and cleverly) split the data to both the ML training and ML inference. As such, this example aims to teach you these concepts in order to complete the following tasks:\n",
        "\n",
        "> 1/ Assuming you have created the class for Data Preprocessing (i.e. Class 1), create **two more separate classes**: **one for ML Training** (i.e. Class 2) that uses _chunks of data between Class 1 and Class 2_, and **another for ML Inference** (i.e. Class 3) that uses a _single datapoint between Class 1 and Class 3_.\n",
        ">\n",
        "> 2/ Now, assuming that there is no concurrency between Class 1 and Class 2 as well as between Class 1 and Class 3, find a way to introduce **two new shared memories** (one memory between Class 1 and 2, and one memory between Class 1 and 3) with _limited capacity_ like in the sensor-processor co-simulation example. For this, you can assume that **Class 1 is a producer** and that **Classes 2 and 3 are consumers**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42e263d5-eb3a-4ccc-a343-e3abc1adf8dc",
      "metadata": {
        "id": "42e263d5-eb3a-4ccc-a343-e3abc1adf8dc"
      },
      "source": [
        "## Block Diagram of Extended Example\n",
        "Below shows the block diagram of our extended diagram involving the data loader, trainer and inferer. For this example, let us assume that the data has already been preprocessed.\n",
        "\n",
        "> **_Note:_** In this example, the previous 'Memory/Buffer' module from the IoT 'Sensor-Processor' Co-Simulation Example has been renamed 'Data source', though they are nearly identical and still serve entirely the same purpose.\n",
        "\n",
        "<center><img src='loader-trainer-inference-block-diagram.png'/></center>\n",
        "\n",
        "Typically, in ML models, these stages are often ran in the following order:\n",
        "\n",
        "1) Loading (and pre-processing) the data.\n",
        "2) Training the ML model using this data.\n",
        "3) Infering the ML model using this data.\n",
        "\n",
        "One possible interesting (and potentially optimizable) approach is to turn the training and inference of the ML model into **concurrent processes**.\n",
        "\n",
        "> **_Note:_** While parallelism can be seen as a form of concurrency, concurrency however cannot be seen as a form of parallelism. This is because concurrency does not necessarily mean to perform every task of a system at the same time, but rather to have the **ability to perform multiple tasks at the same time** (e.g. performing *1 or more* tasks as opposed to **sequential** meaning *1 task at a time* and **parallelism** usually meaning *more than 1 task at a time*).\n",
        "\n",
        "A key question from this is: **_How can we turn these sequential operations into concurrent ones?_**\n",
        "\n",
        "To understand the procedure needed, let us start from a sequential implementation and slowly modify each stage to transform it into a (sufficiently) concurrent implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dfa3d07-1c60-4fef-8fcf-3d5c78cb57f9",
      "metadata": {
        "id": "7dfa3d07-1c60-4fef-8fcf-3d5c78cb57f9"
      },
      "source": [
        "## Timing assumptions of our processes\n",
        "\n",
        "Before we cover the Python code implementations, let us consider the timing of our processes with the following assumptions:\n",
        "\n",
        "- The data loader process requires _1 second_ to add 1 bit/datapoint to the memory.\n",
        "- The trainer reader process requires _5 seconds_ to read 3 bits/datapoints from the memory.\n",
        "- The inferer reader process requires _2 seconds_ to read 1 bit/datapoint from the memory.\n",
        "\n",
        "> **_Note:_** As with any code, the timing values added to these operations are fictional and do not accurately represent the real world, where such timings can vary drastically. The purpose of adding these arbitrary timing values is to mainly show the (theoretical) difference that a concurrent design can make compared to a sequential design, and understand _why_ we need such design choices.\n",
        ">\n",
        "> For example: _Does the ML inference really need to wait for the ML training to finish if their input data are **mutually exclusive**_? We technically do not need to train the model before we infer it, but its obvious that our output will be likely awful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ba3440-1906-4fd3-8d97-27f172270574",
      "metadata": {
        "id": "18ba3440-1906-4fd3-8d97-27f172270574"
      },
      "source": [
        "## Sequential Python Implementation\n",
        "\n",
        "The first, yet simplest, way to implement the above block diagram as Python code is to simply implement each 'process' sequentially like below.\n",
        "\n",
        "As such, the flow of our sequential Python code implementation will be [Data Loader]&#8594;[Trainer]&#8594;[Inferer].\n",
        "\n",
        "> **_Note:_** While we are not explicitly creating any threads nor functions for our data loader, trainer and inferer, the operations that are shown below will follow the exact order in how each process will behave, e.g. this should code should (nearly) behave in the exact same way as if we created each thread but have trainer wait for data loader to join and have inferer wait for both data loader and trainer to join, and if we created the functions for each process but ran the function in the same order of data loader then trainer then inferer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c98cdc-af4b-4943-892c-404d53b24277",
      "metadata": {
        "id": "02c98cdc-af4b-4943-892c-404d53b24277",
        "outputId": "c6cb2674-f731-4419-9f4a-9e614dd0898a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CONSOLE] Operation started.\n",
            "Loader added datapoint:  50  to data index:  1\n",
            "Loader added datapoint:  98  to data index:  2\n",
            "Loader added datapoint:  54  to data index:  3\n",
            "Loader added datapoint:  6  to data index:  4\n",
            "Loader added datapoint:  34  to data index:  5\n",
            "Loader added datapoint:  66  to data index:  6\n",
            "Loader added datapoint:  63  to data index:  7\n",
            "Loader added datapoint:  52  to data index:  8\n",
            "Loader added datapoint:  39  to data index:  9\n",
            "Loader added datapoint:  62  to data index:  10\n",
            "Loader added datapoint:  46  to data index:  11\n",
            "Loader added datapoint:  75  to data index:  12\n",
            "Loader added datapoint:  28  to data index:  13\n",
            "Loader added datapoint:  65  to data index:  14\n",
            "Loader added datapoint:  18  to data index:  15\n",
            "Loader has taken  15.113819360733032  seconds to complete\n",
            "Trainer read datapoints:  [50, 98, 54]  from indices:  1  to  3\n",
            "Trainer read datapoints:  [6, 34, 66]  from indices:  4  to  6\n",
            "Trainer read datapoints:  [63, 52, 39]  from indices:  7  to  9\n",
            "Trainer read datapoints:  [62, 46, 75]  from indices:  10  to  12\n",
            "Trainer read datapoints:  [28, 65, 18]  from indices:  13  to  15\n",
            "Trainer has taken  25.052038192749023  seconds to complete\n",
            "Inferer read datapoint:  50  from data index:  1\n",
            "Inferer read datapoint:  98  from data index:  2\n",
            "Inferer read datapoint:  54  from data index:  3\n",
            "Inferer read datapoint:  6  from data index:  4\n",
            "Inferer read datapoint:  34  from data index:  5\n",
            "Inferer read datapoint:  66  from data index:  6\n",
            "Inferer read datapoint:  63  from data index:  7\n",
            "Inferer read datapoint:  52  from data index:  8\n",
            "Inferer read datapoint:  39  from data index:  9\n",
            "Inferer read datapoint:  62  from data index:  10\n",
            "Inferer read datapoint:  46  from data index:  11\n",
            "Inferer read datapoint:  75  from data index:  12\n",
            "Inferer read datapoint:  28  from data index:  13\n",
            "Inferer read datapoint:  65  from data index:  14\n",
            "Inferer read datapoint:  18  from data index:  15\n",
            "Inferer has taken  30.10369110107422  seconds to complete\n",
            "[CONSOLE] Operation completed.\n",
            "[CONSOLE] Total operation time taken is  70.27154684066772\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "CAPACITY = 15\n",
        "DATALOADER_LOAD_THRESHOLD = 1\n",
        "TRAINER_READ_THRESHOLD = 3\n",
        "INFERER_READ_THRESHOLD = 1\n",
        "\n",
        "DATALOADER_WAIT_TIME = 1\n",
        "TRAINER_WAIT_TIME = 5\n",
        "INFERER_WAIT_TIME = 2\n",
        "\n",
        "data = [-1 for i in range(CAPACITY)]\n",
        "\n",
        "print('[CONSOLE] Operation started.')\n",
        "\n",
        "main_start_time = time.time()\n",
        "\n",
        "# Producer 1 operation -- DataLoader\n",
        "start_time = time.time()\n",
        "datapoints_loaded = 0\n",
        "in_index = 0\n",
        "while datapoints_loaded < CAPACITY:\n",
        "    datapoint = random.randint(1, 100)\n",
        "    data[in_index] = datapoint\n",
        "    print(\"Loader added datapoint: \", str(datapoint), \" to data index: \", str(in_index + 1))\n",
        "    in_index = (in_index + DATALOADER_LOAD_THRESHOLD) % CAPACITY\n",
        "    datapoints_loaded += DATALOADER_LOAD_THRESHOLD\n",
        "    time.sleep(DATALOADER_WAIT_TIME)\n",
        "end_time = time.time()\n",
        "print(\"Loader has taken \", str(end_time - start_time), \" seconds to complete\")\n",
        "\n",
        "# Consumer 1 operation -- Trainer, reads 5 datapoints\n",
        "start_time = time.time()\n",
        "read_datapoints_in_trainer = 0\n",
        "out_index_trainer = 0\n",
        "while read_datapoints_in_trainer < CAPACITY:\n",
        "    trainer_data_to_load = []\n",
        "    for i in range(out_index_trainer, out_index_trainer + 3):\n",
        "        trainer_data_to_load += [data[i]]\n",
        "    print(\"Trainer read datapoints: \", str(trainer_data_to_load), \" from indices: \", str(out_index_trainer + 1), \" to \", str(out_index_trainer + 3))\n",
        "    out_index_trainer = (out_index_trainer + TRAINER_READ_THRESHOLD) % CAPACITY\n",
        "    read_datapoints_in_trainer += TRAINER_READ_THRESHOLD\n",
        "    time.sleep(TRAINER_WAIT_TIME)\n",
        "end_time = time.time()\n",
        "print(\"Trainer has taken \", str(end_time - start_time), \" seconds to complete\")\n",
        "\n",
        "# Consumer 2 operation -- Inference, reads a single datapoint\n",
        "start_time = time.time()\n",
        "read_datapoints_in_inferer = 0\n",
        "out_index_inferer = 0\n",
        "while read_datapoints_in_inferer < CAPACITY:\n",
        "    inferer_data_to_load = data[out_index_inferer]\n",
        "    print(\"Inferer read datapoint: \", str(inferer_data_to_load), \" from data index: \", str(out_index_inferer + 1))\n",
        "    out_index_trainer = (out_index_trainer + INFERER_READ_THRESHOLD) % CAPACITY\n",
        "    read_datapoints_in_inferer += INFERER_READ_THRESHOLD\n",
        "    out_index_inferer += 1\n",
        "    time.sleep(INFERER_WAIT_TIME)\n",
        "end_time = time.time()\n",
        "print(\"Inferer has taken \", str(end_time - start_time), \" seconds to complete\")\n",
        "\n",
        "main_end_time = time.time()\n",
        "\n",
        "print('[CONSOLE] Operation completed.')\n",
        "print('[CONSOLE] Total operation time taken is ', str(main_end_time - main_start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d7d43b-4ad8-4ff2-a19b-475f646932a6",
      "metadata": {
        "id": "40d7d43b-4ad8-4ff2-a19b-475f646932a6"
      },
      "source": [
        "## Initial Concurrent Python Implementation\n",
        "\n",
        "When investigating the code, it is quite clear that we have a bottleneck from running these processes sequentially.\n",
        "\n",
        "One way to improve this implementation is to introduce some concurrency to it, using the concepts we shown last week - i.e. the use of mutexes and sempahores through Python's threading library.\n",
        "\n",
        "With this change, the flow of our initial concurrent Python code implementation start from [Data Loader] and peform a *choice* of either: 1) [Data Loader] to add more data points, 2) [Trainer] if there is at least 3 data points stored, or 3) [Inferer] if there is at least 1 data point stored.\n",
        "\n",
        "By introducing these concepts, our Python code should now resemble the block diagram below.\n",
        "\n",
        "<center><img src='loader-trainer-inference-block-diagram-concurrent.png' /></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31018e3-d56e-4f30-8e5b-4fd8372d7ec1",
      "metadata": {
        "id": "c31018e3-d56e-4f30-8e5b-4fd8372d7ec1",
        "outputId": "266d5977-ac2f-4ea3-d4ac-dc719a395bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CONSOLE] Operation started.\n",
            "Loader  self.name='Thread-3'  added datapoint:  50  to data index:  1\n",
            "Loader  self.name='Thread-3'  added datapoint:  98  to data index:  2\n",
            "Inferer self.name='Thread-5' read datapoint:  50  from data index:  1\n",
            "Loader  self.name='Thread-3'  added datapoint:  54  to data index:  3\n",
            "Loader  self.name='Thread-3'  added datapoint:  6  to data index:  4\n",
            "Inferer self.name='Thread-5' read datapoint:  98  from data index:  2\n",
            "Trainer  self.name='Thread-4' read datapoints:  [50, 98, 54]  from data indices:  1  to  3\n",
            "Loader  self.name='Thread-3'  added datapoint:  34  to data index:  5\n",
            "Inferer self.name='Thread-5' read datapoint:  54  from data index:  3\n",
            "Loader  self.name='Thread-3'  added datapoint:  66  to data index:  6\n",
            "Loader  self.name='Thread-3'  added datapoint:  63  to data index:  7\n",
            "Loader  self.name='Thread-3'  added datapoint:  52  to data index:  8\n",
            "Inferer self.name='Thread-5' read datapoint:  6  from data index:  4\n",
            "Loader  self.name='Thread-3'  added datapoint:  39  to data index:  9\n",
            "Trainer  self.name='Thread-4' read datapoints:  [6, 34, 66]  from data indices:  4  to  6\n",
            "Loader  self.name='Thread-3'  added datapoint:  62  to data index:  10\n",
            "Inferer self.name='Thread-5' read datapoint:  34  from data index:  5\n",
            "Loader  self.name='Thread-3'  added datapoint:  46  to data index:  11\n",
            "Loader  self.name='Thread-3'  added datapoint:  75  to data index:  12\n",
            "Inferer self.name='Thread-5' read datapoint:  66  from data index:  6\n",
            "Loader  self.name='Thread-3'  added datapoint:  28  to data index:  13\n",
            "Loader  self.name='Thread-3'  added datapoint:  65  to data index:  14\n",
            "Inferer self.name='Thread-5' read datapoint:  63  from data index:  7\n",
            "Trainer  self.name='Thread-4' read datapoints:  [63, 52, 39]  from data indices:  7  to  9\n",
            "Loader  self.name='Thread-3'  added datapoint:  18  to data index:  15\n",
            "Loader  self.name='Thread-3'  completed in  15.090566158294678  seconds\n",
            "Inferer self.name='Thread-5' read datapoint:  52  from data index:  8\n",
            "Inferer self.name='Thread-5' read datapoint:  39  from data index:  9\n",
            "Trainer  self.name='Thread-4' read datapoints:  [62, 46, 75]  from data indices:  10  to  12\n",
            "Inferer self.name='Thread-5' read datapoint:  62  from data index:  10\n",
            "Inferer self.name='Thread-5' read datapoint:  46  from data index:  11\n",
            "Inferer self.name='Thread-5' read datapoint:  75  from data index:  12\n",
            "Trainer  self.name='Thread-4' read datapoints:  [28, 65, 18]  from data indices:  13  to  15\n",
            "Trainer  self.name='Thread-4'  completed in  25.05985164642334  seconds\n",
            "Inferer self.name='Thread-5' read datapoint:  28  from data index:  13\n",
            "Inferer self.name='Thread-5' read datapoint:  65  from data index:  14\n",
            "Inferer self.name='Thread-5' read datapoint:  18  from data index:  15\n",
            "Inferer  self.name='Thread-5'  completed in  30.16478991508484  seconds\n",
            "[CONSOLE] Operation completed.\n",
            "[CONSOLE] Total operation time taken is  30.16478991508484\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import threading\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "CAPACITY = 15\n",
        "DATALOADER_LOAD_THRESHOLD = 1\n",
        "TRAINER_READ_THRESHOLD = 3\n",
        "INFERER_READ_THRESHOLD = 1\n",
        "\n",
        "DATALOADER_WAIT_TIME = 1\n",
        "TRAINER_WAIT_TIME = 5\n",
        "INFERER_WAIT_TIME = 2\n",
        "\n",
        "data = [-1 for i in range(CAPACITY)]\n",
        "\n",
        "mutex = threading.Semaphore()\n",
        "empty1 = threading.Semaphore(CAPACITY)\n",
        "empty2 = threading.Semaphore(CAPACITY)\n",
        "full1 = threading.Semaphore(0)\n",
        "full2 = threading.Semaphore(0)\n",
        "\n",
        "# Producer 1 operation -- DataLoader\n",
        "class DataLoader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        datapoints_loaded = 0\n",
        "        in_index = 0\n",
        "        while datapoints_loaded < CAPACITY:\n",
        "\n",
        "            time.sleep(DATALOADER_WAIT_TIME)\n",
        "\n",
        "            empty1.acquire()\n",
        "            empty2.acquire()\n",
        "            mutex.acquire()\n",
        "\n",
        "            datapoint = random.randint(1, 100)\n",
        "            data[in_index] = datapoint\n",
        "            print(\"Loader \" , str(f'{self.name=}'), \" added datapoint: \", str(datapoint), \" to data index: \", str(in_index + 1))\n",
        "            in_index = (in_index + DATALOADER_LOAD_THRESHOLD) % CAPACITY\n",
        "            datapoints_loaded += DATALOADER_LOAD_THRESHOLD\n",
        "\n",
        "            mutex.release()\n",
        "            full1.release()\n",
        "            full2.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Loader \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "# Consumer 1 operation -- Trainer, reads 5 datapoints\n",
        "# class TrainerReader(threading.Thread):\n",
        "class TrainerReader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        read_datapoints_in_trainer = 0\n",
        "        out_index_trainer = 0\n",
        "        while read_datapoints_in_trainer < CAPACITY:\n",
        "\n",
        "            time.sleep(TRAINER_WAIT_TIME)\n",
        "\n",
        "            t_counter = TRAINER_READ_THRESHOLD\n",
        "            while t_counter > 0:\n",
        "                full1.acquire()\n",
        "                t_counter -= 1\n",
        "            mutex.acquire()\n",
        "\n",
        "            trainer_data_to_load = []\n",
        "            for i in range(out_index_trainer, out_index_trainer + 3):\n",
        "                trainer_data_to_load += [data[i]]\n",
        "            print(\"Trainer \", str(f'{self.name=}'), \"read datapoints: \", str(trainer_data_to_load), \" from data indices: \", str(out_index_trainer + 1), \" to \", str(out_index_trainer + 3))\n",
        "            out_index_trainer = (out_index_trainer + TRAINER_READ_THRESHOLD) % CAPACITY\n",
        "            read_datapoints_in_trainer += TRAINER_READ_THRESHOLD\n",
        "\n",
        "            mutex.release()\n",
        "            for i in range(TRAINER_READ_THRESHOLD):\n",
        "                empty1.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Trainer \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "# Consumer 2 operation -- Inference, reads a single datapoint\n",
        "class InfererReader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        read_datapoints_in_inferer = 0\n",
        "        out_index_inferer = 0\n",
        "        while read_datapoints_in_inferer < CAPACITY:\n",
        "\n",
        "            time.sleep(INFERER_WAIT_TIME)\n",
        "\n",
        "            i_counter = INFERER_READ_THRESHOLD\n",
        "            while i_counter > 0:\n",
        "                full2.acquire()\n",
        "                i_counter -= 1\n",
        "            mutex.acquire()\n",
        "\n",
        "            inferer_data_to_load = data[out_index_inferer]\n",
        "            print(\"Inferer\", str(f'{self.name=}'), \"read datapoint: \", str(inferer_data_to_load), \" from data index: \", str(out_index_inferer + 1))\n",
        "            out_index_inferer = (out_index_inferer + INFERER_READ_THRESHOLD) % CAPACITY\n",
        "            read_datapoints_in_inferer += INFERER_READ_THRESHOLD\n",
        "\n",
        "            mutex.release()\n",
        "            for i in range(INFERER_READ_THRESHOLD):\n",
        "                empty2.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Inferer \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "print('[CONSOLE] Operation started.')\n",
        "\n",
        "main_start_time = time.time()\n",
        "\n",
        "# Creating Threads\n",
        "data_load = DataLoader()\n",
        "train_read = TrainerReader()\n",
        "infer_read = InfererReader()\n",
        "\n",
        "# Starting Threads\n",
        "data_load.start()\n",
        "train_read.start()\n",
        "infer_read.start()\n",
        "\n",
        "# Waiting for threads to complete\n",
        "data_load.join()\n",
        "train_read.join()\n",
        "infer_read.join()\n",
        "\n",
        "main_end_time = time.time()\n",
        "\n",
        "print('[CONSOLE] Operation completed.')\n",
        "print('[CONSOLE] Total operation time taken is ', str(main_end_time - main_start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f1bff1-9dd0-4467-9168-729aa6dde382",
      "metadata": {
        "id": "69f1bff1-9dd0-4467-9168-729aa6dde382"
      },
      "source": [
        "## Extended Concurrent Python Implementation\n",
        "\n",
        "Although we have introduced some concurrency, there is still some sequential behaviour within the system that we can further transform concurrently, i.e. when [Trainer Reader] is reading data and when [Inferer Reader] is reading data.\n",
        "\n",
        "In the current case, the *mutex* semaphore ensures that only one of the processes can run at the time meaning there is some sequential dependency between [Trainer Reader] and [Inferer Reader]. In fact, both these processes are using the same data that is occupied same memory, which may cause conflicts as this can lead to potential race conditions.\n",
        "\n",
        "One possible way to resolve this is by carefully removing this dependency by introducing an additional memory, such that one memory is shared between only the [Data Loader] and [Trainer Reader] and one memory is shared between only the [Data Loader] and [Inferer Reader].\n",
        "\n",
        "> **_Note:_** Technically, you can just remove the mutex and remove this sequential dependency entirely. However, as discussed in Lab 4's example, this will allow the data to be corrupted (due to multiple reads/writes happening) and allow the data to be read too early leading to errors and/or stale data (due to no writes).\n",
        ">\n",
        "> In this case, while the following solution does not solve problematic race conditions, the intention of this example is to give you an idea on how you can split up the actions of the ML training and ML inference by carefully considering the design of the data propagation, e.g. using two copies of data can allow both training and inference to take place - but, how this impacts the training and inference is still something to explore in your own time.\n",
        "\n",
        "With this additional change, the flow of our extended concurrent Python code implementation start from [Data Loader] and peform two *choices*, where the first consists of either: 1) [Data Loader] to add more data points or [Trainer] if there is at least 3 data points stored, and the second consists of either 1) [Data Loader] to add more data points or 2) [Inferer] if there is at least 1 data point stored.\n",
        "\n",
        "Again, with this change in our Python code, it should now resemble this block diagram below.\n",
        "\n",
        "<center><img src='loader-trainer-inference-block-diagram-concurrent-two-memory.png' /></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc0d631-1202-40a2-b4a3-a534e5b0ca6d",
      "metadata": {
        "id": "cdc0d631-1202-40a2-b4a3-a534e5b0ca6d",
        "outputId": "0d8de808-13fe-4ea1-d4c5-3a885aac0743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CONSOLE] Operation started.\n",
            "Loader  self.name='Thread-6'  added datapoint:  50  to data1 and data2 index:  1\n",
            "Inferer self.name='Thread-8' read datapoint:  50  from data2 index:  1\n",
            "Loader  self.name='Thread-6'  added datapoint:  98  to data1 and data2 index:  2\n",
            "Loader  self.name='Thread-6'  added datapoint:  54  to data1 and data2 index:  3\n",
            "Inferer self.name='Thread-8' read datapoint:  98  from data2 index:  2\n",
            "Loader  self.name='Thread-6'  added datapoint:  6  to data1 and data2 index:  4\n",
            "Trainer  self.name='Thread-7' read datapoints:  [50, 98, 54]  from data1 indices:  1  to  3\n",
            "Loader  self.name='Thread-6'  added datapoint:  34  to data1 and data2 index:  5\n",
            "Inferer self.name='Thread-8' read datapoint:  54  from data2 index:  3\n",
            "Loader  self.name='Thread-6'  added datapoint:  66  to data1 and data2 index:  6\n",
            "Loader  self.name='Thread-6'  added datapoint:  63  to data1 and data2 index:  7\n",
            "Inferer self.name='Thread-8' read datapoint:  6  from data2 index:  4\n",
            "Loader  self.name='Thread-6'  added datapoint:  52  to data1 and data2 index:  8\n",
            "Loader  self.name='Thread-6'  added datapoint:  39  to data1 and data2 index:  9\n",
            "Trainer  self.name='Thread-7' read datapoints:  [6, 34, 66]  from data1 indices:  4  to  6\n",
            "Inferer self.name='Thread-8' read datapoint:  34  from data2 index:  5\n",
            "Loader  self.name='Thread-6'  added datapoint:  62  to data1 and data2 index:  10\n",
            "Loader  self.name='Thread-6'  added datapoint:  46  to data1 and data2 index:  11\n",
            "Inferer self.name='Thread-8' read datapoint:  66  from data2 index:  6\n",
            "Loader  self.name='Thread-6'  added datapoint:  75  to data1 and data2 index:  12\n",
            "Loader  self.name='Thread-6'  added datapoint:  28  to data1 and data2 index:  13\n",
            "Inferer self.name='Thread-8' read datapoint:  63  from data2 index:  7\n",
            "Loader  self.name='Thread-6'  added datapoint:  65  to data1 and data2 index:  14\n",
            "Trainer  self.name='Thread-7' read datapoints:  [63, 52, 39]  from data1 indices:  7  to  9\n",
            "Loader  self.name='Thread-6'  added datapoint:  18  to data1 and data2 index:  15\n",
            "Loader  self.name='Thread-6'  completed in  15.126014947891235  seconds\n",
            "Inferer self.name='Thread-8' read datapoint:  52  from data2 index:  8\n",
            "Inferer self.name='Thread-8' read datapoint:  39  from data2 index:  9\n",
            "Trainer  self.name='Thread-7' read datapoints:  [62, 46, 75]  from data1 indices:  10  to  12\n",
            "Inferer self.name='Thread-8' read datapoint:  62  from data2 index:  10\n",
            "Inferer self.name='Thread-8' read datapoint:  46  from data2 index:  11\n",
            "Inferer self.name='Thread-8' read datapoint:  75  from data2 index:  12\n",
            "Trainer  self.name='Thread-7' read datapoints:  [28, 65, 18]  from data1 indices:  13  to  15\n",
            "Trainer  self.name='Thread-7'  completed in  25.059722185134888  seconds\n",
            "Inferer self.name='Thread-8' read datapoint:  28  from data2 index:  13\n",
            "Inferer self.name='Thread-8' read datapoint:  65  from data2 index:  14\n",
            "Inferer self.name='Thread-8' read datapoint:  18  from data2 index:  15\n",
            "Inferer  self.name='Thread-8'  completed in  30.139988899230957  seconds\n",
            "Data 1:\n",
            " [50, 98, 54, 6, 34, 66, 63, 52, 39, 62, 46, 75, 28, 65, 18]\n",
            "Data 2:\n",
            " [50, 98, 54, 6, 34, 66, 63, 52, 39, 62, 46, 75, 28, 65, 18]\n",
            "[CONSOLE] Operation completed.\n",
            "[CONSOLE] Total operation time taken is  30.14403223991394\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import threading\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "CAPACITY = 15\n",
        "DATALOADER_LOAD_THRESHOLD = 1\n",
        "TRAINER_READ_THRESHOLD = 3\n",
        "INFERER_READ_THRESHOLD = 1\n",
        "\n",
        "DATALOADER_WAIT_TIME = 1\n",
        "TRAINER_WAIT_TIME = 5\n",
        "INFERER_WAIT_TIME = 2\n",
        "\n",
        "TEST_MEMORIES_WITH_DIFFERENT_DATA = False\n",
        "\n",
        "data1 = [-1 for i in range(CAPACITY)]\n",
        "data2 = [-1 for i in range(CAPACITY)]\n",
        "\n",
        "mutex1 = threading.Semaphore()\n",
        "mutex2 = threading.Semaphore()\n",
        "empty1 = threading.Semaphore(CAPACITY)\n",
        "empty2 = threading.Semaphore(CAPACITY)\n",
        "full1 = threading.Semaphore(0)\n",
        "full2 = threading.Semaphore(0)\n",
        "\n",
        "# Producer 1 operation -- DataLoader\n",
        "class DataLoader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        datapoints_loaded = 0\n",
        "        in_index = 0\n",
        "        while datapoints_loaded < CAPACITY:\n",
        "\n",
        "            time.sleep(DATALOADER_WAIT_TIME)\n",
        "\n",
        "            empty1.acquire()\n",
        "            empty2.acquire()\n",
        "            mutex1.acquire()\n",
        "            mutex2.acquire()\n",
        "\n",
        "            datapoint = random.randint(1, 100)\n",
        "            data1[in_index] = datapoint\n",
        "\n",
        "            if TEST_MEMORIES_WITH_DIFFERENT_DATA:\n",
        "                datapoint2 = random.randint(1, 100) # Proof of concept\n",
        "                data2[in_index] = datapoint2\n",
        "                print(\"Loader \" , str(f'{self.name=}'), \" added datapoint: \", str(datapoint), \" to data1 index: \", str(in_index + 1),\n",
        "                      \" and added datapoint: \", str(datapoint2), \" to data2 index: \", str(in_index+1))\n",
        "            else:\n",
        "                data2[in_index] = datapoint\n",
        "                print(\"Loader \" , str(f'{self.name=}'), \" added datapoint: \", str(datapoint), \" to data1 and data2 index: \", str(in_index + 1))\n",
        "\n",
        "            in_index = (in_index + DATALOADER_LOAD_THRESHOLD) % CAPACITY\n",
        "            datapoints_loaded += DATALOADER_LOAD_THRESHOLD\n",
        "\n",
        "            mutex1.release()\n",
        "            mutex2.release()\n",
        "            full1.release()\n",
        "            full2.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Loader \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "# Consumer 1 operation -- Trainer, reads 5 datapoints\n",
        "# class TrainerReader(threading.Thread):\n",
        "class TrainerReader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        read_datapoints_in_trainer = 0\n",
        "        out_index_trainer = 0\n",
        "        while read_datapoints_in_trainer < CAPACITY:\n",
        "\n",
        "            time.sleep(TRAINER_WAIT_TIME)\n",
        "\n",
        "            t_counter = TRAINER_READ_THRESHOLD\n",
        "            while t_counter > 0:\n",
        "                full1.acquire()\n",
        "                t_counter -= 1\n",
        "            mutex1.acquire()\n",
        "\n",
        "            trainer_data_to_load = []\n",
        "            for i in range(out_index_trainer, out_index_trainer + 3):\n",
        "                trainer_data_to_load += [data1[i]]\n",
        "            print(\"Trainer \", str(f'{self.name=}'), \"read datapoints: \", str(trainer_data_to_load), \" from data1 indices: \", str(out_index_trainer + 1), \" to \", str(out_index_trainer + 3))\n",
        "            out_index_trainer = (out_index_trainer + TRAINER_READ_THRESHOLD) % CAPACITY\n",
        "            read_datapoints_in_trainer += TRAINER_READ_THRESHOLD\n",
        "\n",
        "            mutex1.release()\n",
        "            for i in range(TRAINER_READ_THRESHOLD):\n",
        "                empty1.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Trainer \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "# Consumer 2 operation -- Inference, reads a single datapoint\n",
        "class InfererReader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        read_datapoints_in_inferer = 0\n",
        "        out_index_inferer = 0\n",
        "        while read_datapoints_in_inferer < CAPACITY:\n",
        "\n",
        "            time.sleep(INFERER_WAIT_TIME)\n",
        "\n",
        "            i_counter = INFERER_READ_THRESHOLD\n",
        "            while i_counter > 0:\n",
        "                full2.acquire()\n",
        "                i_counter -= 1\n",
        "            mutex2.acquire()\n",
        "\n",
        "            inferer_data_to_load = data2[out_index_inferer]\n",
        "            print(\"Inferer\", str(f'{self.name=}'), \"read datapoint: \", str(inferer_data_to_load), \" from data2 index: \", str(out_index_inferer + 1))\n",
        "            out_index_inferer = (out_index_inferer + INFERER_READ_THRESHOLD) % CAPACITY\n",
        "            read_datapoints_in_inferer += INFERER_READ_THRESHOLD\n",
        "\n",
        "            mutex2.release()\n",
        "            for i in range(INFERER_READ_THRESHOLD):\n",
        "                empty2.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Inferer \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "print('[CONSOLE] Operation started.')\n",
        "\n",
        "main_start_time = time.time()\n",
        "\n",
        "# Creating Threads\n",
        "data_load = DataLoader()\n",
        "train_read = TrainerReader()\n",
        "infer_read = InfererReader()\n",
        "\n",
        "# Starting Threads\n",
        "data_load.start()\n",
        "train_read.start()\n",
        "infer_read.start()\n",
        "\n",
        "# Waiting for threads to complete\n",
        "data_load.join()\n",
        "train_read.join()\n",
        "infer_read.join()\n",
        "\n",
        "print(\"Data 1:\\n\", data1)\n",
        "print(\"Data 2:\\n\", data2)\n",
        "\n",
        "main_end_time = time.time()\n",
        "\n",
        "print('[CONSOLE] Operation completed.')\n",
        "print('[CONSOLE] Total operation time taken is ', str(main_end_time - main_start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a117be0-f25f-4950-a253-dece14aa6658",
      "metadata": {
        "id": "8a117be0-f25f-4950-a253-dece14aa6658"
      },
      "source": [
        "## Extended Concurrent Python Implementation (Cont.)\n",
        "\n",
        "Just as a proof of concept, the above code was slightly modified to show it working where the data between Data Loader and Trainer Reader are different to the data between Data Loader and Inferer Reader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e22449-8bd9-413a-9f48-80391d955122",
      "metadata": {
        "id": "f3e22449-8bd9-413a-9f48-80391d955122",
        "outputId": "1110b256-17a7-4449-e692-d251ca067180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CONSOLE] Operation started.\n",
            "Loader  self.name='Thread-9'  added datapoint:  50  to data1 index:  1  and added datapoint:  98  to data2 index:  1\n",
            "Inferer self.name='Thread-11' read datapoint:  98  from data2 index:  1\n",
            "Loader  self.name='Thread-9'  added datapoint:  54  to data1 index:  2  and added datapoint:  6  to data2 index:  2\n",
            "Loader  self.name='Thread-9'  added datapoint:  34  to data1 index:  3  and added datapoint:  66  to data2 index:  3\n",
            "Inferer self.name='Thread-11' read datapoint:  6  from data2 index:  2\n",
            "Loader  self.name='Thread-9'  added datapoint:  63  to data1 index:  4  and added datapoint:  52  to data2 index:  4\n",
            "Trainer  self.name='Thread-10' read datapoints:  [50, 54, 34]  from data1 indices:  1  to  3\n",
            "Loader  self.name='Thread-9'  added datapoint:  39  to data1 index:  5  and added datapoint:  62  to data2 index:  5\n",
            "Inferer self.name='Thread-11' read datapoint:  66  from data2 index:  3\n",
            "Loader  self.name='Thread-9'  added datapoint:  46  to data1 index:  6  and added datapoint:  75  to data2 index:  6\n",
            "Loader  self.name='Thread-9'  added datapoint:  28  to data1 index:  7  and added datapoint:  65  to data2 index:  7\n",
            "Inferer self.name='Thread-11' read datapoint:  52  from data2 index:  4\n",
            "Loader  self.name='Thread-9'  added datapoint:  18  to data1 index:  8  and added datapoint:  37  to data2 index:  8\n",
            "Loader  self.name='Thread-9'  added datapoint:  18  to data1 index:  9  and added datapoint:  97  to data2 index:  9\n",
            "Trainer  self.name='Thread-10' read datapoints:  [63, 39, 46]  from data1 indices:  4  to  6\n",
            "Inferer self.name='Thread-11' read datapoint:  62  from data2 index:  5\n",
            "Loader  self.name='Thread-9'  added datapoint:  13  to data1 index:  10  and added datapoint:  80  to data2 index:  10\n",
            "Loader  self.name='Thread-9'  added datapoint:  33  to data1 index:  11  and added datapoint:  69  to data2 index:  11\n",
            "Inferer self.name='Thread-11' read datapoint:  75  from data2 index:  6\n",
            "Loader  self.name='Thread-9'  added datapoint:  91  to data1 index:  12  and added datapoint:  78  to data2 index:  12\n",
            "Loader  self.name='Thread-9'  added datapoint:  19  to data1 index:  13  and added datapoint:  40  to data2 index:  13\n",
            "Inferer self.name='Thread-11' read datapoint:  65  from data2 index:  7\n",
            "Loader  self.name='Thread-9'  added datapoint:  13  to data1 index:  14  and added datapoint:  94  to data2 index:  14\n",
            "Trainer  self.name='Thread-10' read datapoints:  [28, 18, 18]  from data1 indices:  7  to  9\n",
            "Loader  self.name='Thread-9'  added datapoint:  10  to data1 index:  15  and added datapoint:  88  to data2 index:  15\n",
            "Loader  self.name='Thread-9'  completed in  15.122904539108276  seconds\n",
            "Inferer self.name='Thread-11' read datapoint:  37  from data2 index:  8\n",
            "Inferer self.name='Thread-11' read datapoint:  97  from data2 index:  9\n",
            "Trainer  self.name='Thread-10' read datapoints:  [13, 33, 91]  from data1 indices:  10  to  12\n",
            "Inferer self.name='Thread-11' read datapoint:  80  from data2 index:  10\n",
            "Inferer self.name='Thread-11' read datapoint:  69  from data2 index:  11\n",
            "Inferer self.name='Thread-11' read datapoint:  78  from data2 index:  12\n",
            "Trainer  self.name='Thread-10' read datapoints:  [19, 13, 10]  from data1 indices:  13  to  15\n",
            "Trainer  self.name='Thread-10'  completed in  25.038170337677002  seconds\n",
            "Inferer self.name='Thread-11' read datapoint:  40  from data2 index:  13\n",
            "Inferer self.name='Thread-11' read datapoint:  94  from data2 index:  14\n",
            "Inferer self.name='Thread-11' read datapoint:  88  from data2 index:  15\n",
            "Inferer  self.name='Thread-11'  completed in  30.1708881855011  seconds\n",
            "Data 1:\n",
            " [50, 54, 34, 63, 39, 46, 28, 18, 18, 13, 33, 91, 19, 13, 10]\n",
            "Data 2:\n",
            " [98, 6, 66, 52, 62, 75, 65, 37, 97, 80, 69, 78, 40, 94, 88]\n",
            "[CONSOLE] Operation completed.\n",
            "[CONSOLE] Total operation time taken is  30.171905279159546\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import random\n",
        "import threading\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "CAPACITY = 15\n",
        "DATALOADER_LOAD_THRESHOLD = 1\n",
        "TRAINER_READ_THRESHOLD = 3\n",
        "INFERER_READ_THRESHOLD = 1\n",
        "\n",
        "DATALOADER_WAIT_TIME = 1\n",
        "TRAINER_WAIT_TIME = 5\n",
        "INFERER_WAIT_TIME = 2\n",
        "\n",
        "TEST_MEMORIES_WITH_DIFFERENT_DATA = True\n",
        "\n",
        "data1 = [-1 for i in range(CAPACITY)]\n",
        "data2 = [-1 for i in range(CAPACITY)]\n",
        "\n",
        "mutex1 = threading.Semaphore()\n",
        "mutex2 = threading.Semaphore()\n",
        "empty1 = threading.Semaphore(CAPACITY)\n",
        "empty2 = threading.Semaphore(CAPACITY)\n",
        "full1 = threading.Semaphore(0)\n",
        "full2 = threading.Semaphore(0)\n",
        "\n",
        "# Producer 1 operation -- DataLoader\n",
        "class DataLoader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        datapoints_loaded = 0\n",
        "        in_index = 0\n",
        "        while datapoints_loaded < CAPACITY:\n",
        "\n",
        "            time.sleep(DATALOADER_WAIT_TIME)\n",
        "\n",
        "            empty1.acquire()\n",
        "            empty2.acquire()\n",
        "            mutex1.acquire()\n",
        "            mutex2.acquire()\n",
        "\n",
        "            datapoint = random.randint(1, 100)\n",
        "            data1[in_index] = datapoint\n",
        "\n",
        "            if TEST_MEMORIES_WITH_DIFFERENT_DATA:\n",
        "                datapoint2 = random.randint(1, 100) # Proof of concept\n",
        "                data2[in_index] = datapoint2\n",
        "                print(\"Loader \" , str(f'{self.name=}'), \" added datapoint: \", str(datapoint), \" to data1 index: \", str(in_index + 1),\n",
        "                      \" and added datapoint: \", str(datapoint2), \" to data2 index: \", str(in_index+1))\n",
        "            else:\n",
        "                data2[in_index] = datapoint\n",
        "                print(\"Loader \" , str(f'{self.name=}'), \" added datapoint: \", str(datapoint), \" to data1 and data2 index: \", str(in_index + 1))\n",
        "\n",
        "            in_index = (in_index + DATALOADER_LOAD_THRESHOLD) % CAPACITY\n",
        "            datapoints_loaded += DATALOADER_LOAD_THRESHOLD\n",
        "\n",
        "            mutex1.release()\n",
        "            mutex2.release()\n",
        "            full1.release()\n",
        "            full2.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Loader \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "# Consumer 1 operation -- Trainer, reads 5 datapoints\n",
        "# class TrainerReader(threading.Thread):\n",
        "class TrainerReader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        read_datapoints_in_trainer = 0\n",
        "        out_index_trainer = 0\n",
        "        while read_datapoints_in_trainer < CAPACITY:\n",
        "\n",
        "            time.sleep(TRAINER_WAIT_TIME)\n",
        "\n",
        "            t_counter = TRAINER_READ_THRESHOLD\n",
        "            while t_counter > 0:\n",
        "                full1.acquire()\n",
        "                t_counter -= 1\n",
        "            mutex1.acquire()\n",
        "\n",
        "            trainer_data_to_load = []\n",
        "            for i in range(out_index_trainer, out_index_trainer + 3):\n",
        "                trainer_data_to_load += [data1[i]]\n",
        "            print(\"Trainer \", str(f'{self.name=}'), \"read datapoints: \", str(trainer_data_to_load), \" from data1 indices: \", str(out_index_trainer + 1), \" to \", str(out_index_trainer + 3))\n",
        "            out_index_trainer = (out_index_trainer + TRAINER_READ_THRESHOLD) % CAPACITY\n",
        "            read_datapoints_in_trainer += TRAINER_READ_THRESHOLD\n",
        "\n",
        "            mutex1.release()\n",
        "            for i in range(TRAINER_READ_THRESHOLD):\n",
        "                empty1.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Trainer \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "# Consumer 2 operation -- Inference, reads a single datapoint\n",
        "class InfererReader(threading.Thread):\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        read_datapoints_in_inferer = 0\n",
        "        out_index_inferer = 0\n",
        "        while read_datapoints_in_inferer < CAPACITY:\n",
        "\n",
        "            time.sleep(INFERER_WAIT_TIME)\n",
        "\n",
        "            i_counter = INFERER_READ_THRESHOLD\n",
        "            while i_counter > 0:\n",
        "                full2.acquire()\n",
        "                i_counter -= 1\n",
        "            mutex2.acquire()\n",
        "\n",
        "            inferer_data_to_load = data2[out_index_inferer]\n",
        "            print(\"Inferer\", str(f'{self.name=}'), \"read datapoint: \", str(inferer_data_to_load), \" from data2 index: \", str(out_index_inferer + 1))\n",
        "            out_index_inferer = (out_index_inferer + INFERER_READ_THRESHOLD) % CAPACITY\n",
        "            read_datapoints_in_inferer += INFERER_READ_THRESHOLD\n",
        "\n",
        "            mutex2.release()\n",
        "            for i in range(INFERER_READ_THRESHOLD):\n",
        "                empty2.release()\n",
        "        end_time = time.time()\n",
        "        print(\"Inferer \" , str(f'{self.name=}'), \" completed in \", str(end_time - start_time), \" seconds\")\n",
        "\n",
        "print('[CONSOLE] Operation started.')\n",
        "\n",
        "main_start_time = time.time()\n",
        "\n",
        "# Creating Threads\n",
        "data_load = DataLoader()\n",
        "train_read = TrainerReader()\n",
        "infer_read = InfererReader()\n",
        "\n",
        "# Starting Threads\n",
        "data_load.start()\n",
        "train_read.start()\n",
        "infer_read.start()\n",
        "\n",
        "# Waiting for threads to complete\n",
        "data_load.join()\n",
        "train_read.join()\n",
        "infer_read.join()\n",
        "\n",
        "print(\"Data 1:\\n\", data1)\n",
        "print(\"Data 2:\\n\", data2)\n",
        "\n",
        "main_end_time = time.time()\n",
        "\n",
        "print('[CONSOLE] Operation completed.')\n",
        "print('[CONSOLE] Total operation time taken is ', str(main_end_time - main_start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ece59e-395e-48ee-871f-a2fcf229e590",
      "metadata": {
        "id": "36ece59e-395e-48ee-871f-a2fcf229e590"
      },
      "source": [
        "## How is this all related to today's task?\n",
        "\n",
        "Let us first recall our tasks from the top (which have been copied for your convenience).\n",
        "\n",
        "> 1/ Assuming you have created the class for Data Preprocessing (i.e. Class 1), create **two more separate classes**: **one for ML Training** (i.e. Class 2) that uses _chunks of data between Class 1 and Class 2_, and **another for ML Inference** (i.e. Class 3) that uses a _single datapoint between Class 1 and Class 3_.\n",
        ">\n",
        "> 2/ Now, assuming that there is no concurrency between Class 1 and Class 2 as well as between Class 1 and Class 3, find a way to introduce **two new shared memories** (one memory between Class 1 and 2, and one memory between Class 1 and 3) with _limited capacity_ like in the sensor-processor co-simulation example. For this, you can assume that **Class 1 is a producer** and that **Classes 2 and 3 are consumers**.\n",
        "\n",
        "For 1/: The data containing three datapoints represents the 'chunks of data' that is used in the ML training, and similarly the data containing one datapoint represents the 'datapoint' that is used in the ML inference. In fact, you can even scale this up further by assuming that the 'chunks of data' means several sets of _20 datapoints_ which we use to train our LSTM and that the 'single datapoint' means one set of _20 datapoints_ which we use to infer our LSTM. By carefully considering the design of your framework, your implementation should be (somewhat) susceptible to small rigid changes.\n",
        "\n",
        "For 2/: As we have already shown how the inherent sequential dependency between the trainer and inferer can be slightly alleviated, the key idea for having two memories is that it allows the trainer and inferer to perform their operations without affecting one another, i.e. avoiding the situation where we may have a race condition involving the *mutex semaphore* between the two processes. Of course, this (possibly) will introduce a secondary mutex as the memory between the [Data Loader] and [Trainer Reader], as well as the memory between the [Data Loader] and [Inferer Reader], which must be appropriately handled to avoid further conflicts. But, with this setup, you can essentially slice the data up and feed *individual slices* to **different** processes - these being our ML inference and ML trainer.\n",
        "<center><img src='loader-trainer-inference-block-diagram-orig-data.png' /></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e60d0328-2e87-4522-a434-09a04493c595",
      "metadata": {
        "id": "e60d0328-2e87-4522-a434-09a04493c595"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
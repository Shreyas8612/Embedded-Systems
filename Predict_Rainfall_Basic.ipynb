{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:51.909313Z",
     "start_time": "2025-03-17T21:28:48.515613Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from queue import Queue\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "File_Path = '/Users/shreyasravi/PycharmProjects/Embedded-Systems/London_Weather.csv'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A thread-safe class for preprocessing weather data, implementing feature selection, and preparing data chunks for LSTM training and inference processes. This class acts as a producer in a producer-consumer pattern, sending data to both training and inference threads.\n",
    "\n",
    "Semaphore is like a counter which is used to control the number of threads that can access a shared resource at the same time. It is a signaling mechanism like traffic light block threads when resources are not available and allow threads when the resources are available."
   ],
   "id": "d2c705c3fe36735c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the LSTM, there are three key gates:\n",
    "\n",
    "1. The Forget Gate manages what should be forgotten.\n",
    "2. The Input Gate manages what should be kept, and\n",
    "3. The Output Gate manages what information is stored in the carry and hidden states.\n",
    "\n",
    "Each of these gates comprise of their own neural network layer that handles the mathematics needed to retain the relevant data we need to store in both the short-term memory and long-term memory."
   ],
   "id": "8166177581b8cff8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This class acts as a consumer in the producer-consumer pattern,\n",
    "consuming data from the DataPreprocessing class and training an LSTM model."
   ],
   "id": "b7651ff5ea550d8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Thread-safe class for inferring using a trained LSTM model for weather forecasting.\n",
    "\n",
    "This class acts as a consumer in a producer-consumer pattern, consuming test data\n",
    "from the preprocessing thread and generating predictions using the trained model."
   ],
   "id": "5fb930811a4ed6b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:51.965637Z",
     "start_time": "2025-03-17T21:28:51.917786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.scaler = None\n",
    "        self.normalized_data = None\n",
    "        self.train_size = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.T = 20  # Number of timesteps to look while predicting\n",
    "\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        print(f\"Data loaded with shape: {self.data.shape}\")\n",
    "        return self.data\n",
    "\n",
    "    def clean_data(self):\n",
    "        # Convert date to datetime format\n",
    "        self.data['date'] = pd.to_datetime(self.data['date'], format='%Y%m%d')\n",
    "\n",
    "        # Fill missing values in snow_depth with 0\n",
    "        self.data['snow_depth'].fillna(0, inplace=True)\n",
    "\n",
    "        # Drop rows with any NaN values\n",
    "        self.data.dropna(inplace=True)\n",
    "\n",
    "        print(f\"Data cleaned. New shape: {self.data.shape}\")\n",
    "        return self.data\n",
    "\n",
    "    def prepare_data_for_model(self, train_ratio=0.8, target_column='mean_temp'):\n",
    "        # Separate features and target\n",
    "        input_data = self.data.drop(['date'], axis=1)\n",
    "        targets = self.data[target_column].values\n",
    "\n",
    "        # Define dimensions\n",
    "        D = input_data.shape[1]  # Number of features\n",
    "        N = len(input_data) - self.T\n",
    "\n",
    "        # Calculate train size\n",
    "        self.train_size = int(len(input_data) * train_ratio)\n",
    "\n",
    "        # Normalize input data\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(input_data[:self.train_size + self.T - 1])\n",
    "        self.normalized_data = self.scaler.transform(input_data)\n",
    "\n",
    "        # Prepare X_train and y_train\n",
    "        self.X_train = np.zeros((self.train_size, self.T, D))\n",
    "        self.y_train = np.zeros((self.train_size, 1))\n",
    "\n",
    "        for t in range(self.train_size):\n",
    "            self.X_train[t, :, :] = self.normalized_data[t:t+self.T]\n",
    "            self.y_train[t] = targets[t+self.T]\n",
    "\n",
    "        # Prepare X_test and y_test\n",
    "        self.X_test = np.zeros((N - self.train_size, self.T, D))\n",
    "        self.y_test = np.zeros((N - self.train_size, 1))\n",
    "\n",
    "        for i in range(N - self.train_size):\n",
    "            t = i + self.train_size\n",
    "            self.X_test[i, :, :] = self.normalized_data[t:t+self.T]\n",
    "            self.y_test[i] = targets[t+self.T]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        self.X_train = torch.from_numpy(self.X_train.astype(np.float32))\n",
    "        self.y_train = torch.from_numpy(self.y_train.astype(np.float32))\n",
    "        self.X_test = torch.from_numpy(self.X_test.astype(np.float32))\n",
    "        self.y_test = torch.from_numpy(self.y_test.astype(np.float32))\n",
    "\n",
    "        print(f\"Data prepared for model -> X_train shape: {self.X_train.shape}, y_train shape: {self.y_train.shape}\")\n",
    "        return self.X_train, self.y_train, self.X_test, self.y_test\n",
    "\n",
    "    def get_train_test_data(self):\n",
    "        return self.X_train, self.y_train, self.X_test, self.y_test\n",
    "\n",
    "    def get_original_data(self):\n",
    "        return self.data\n",
    "\n",
    "    def get_scaler(self):\n",
    "        return self.scaler"
   ],
   "id": "e3e01f49def956a7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.054009Z",
     "start_time": "2025-03-17T21:28:52.050982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.M = hidden_dim\n",
    "        self.L = layer_dim\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=layer_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # batch_first to have (batch_dim, seq_dim, feature_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Set device - ideally this would be a class property set during initialization\n",
    "        device = X.device\n",
    "\n",
    "        # Initial hidden state and cell state\n",
    "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "\n",
    "        out, (hn, cn) = self.rnn(X, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # h(T) at the final time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "id": "66411eb210407062",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.067563Z",
     "start_time": "2025-03-17T21:28:52.061682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Training:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\n",
    "                                   \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        self.train_losses = None\n",
    "        self.test_losses = None\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def create_model(self, input_dim, hidden_dim=512, layer_dim=2, output_dim=1):\n",
    "        self.model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "        self.model.to(self.device)\n",
    "        return self.model\n",
    "\n",
    "    def train_model(self, X_train, y_train, X_test, y_test, learning_rate=0.01, epochs=200):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not created. Call create_model first.\")\n",
    "\n",
    "        # Move data to device\n",
    "        X_train, y_train = X_train.to(self.device), y_train.to(self.device)\n",
    "        X_test, y_test = X_test.to(self.device), y_test.to(self.device)\n",
    "\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "        self.train_losses = np.zeros(epochs)\n",
    "        self.test_losses = np.zeros(epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = self.model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Train loss\n",
    "            self.train_losses[epoch] = loss.item()\n",
    "\n",
    "            # Test loss\n",
    "            test_outputs = self.model(X_test)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "            self.test_losses[epoch] = test_loss.item()\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Train Loss: {loss.item():.3f}, Test Loss: {test_loss.item():.3f}')\n",
    "\n",
    "        return self.train_losses, self.test_losses\n",
    "\n",
    "    def save_model(self, model_path, weights_path):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not created. Call create_model first.\")\n",
    "\n",
    "        torch.save(self.model, model_path)\n",
    "        torch.save(self.model.state_dict(), weights_path)\n",
    "        print(f\"Model saved to {model_path} and weights saved to {weights_path}\")\n",
    "\n",
    "    def load_model(self, model_path=None, weights_path=None):\n",
    "        if model_path is not None:\n",
    "            self.model = torch.load(model_path, map_location=self.device)\n",
    "            print(f\"Model loaded from {model_path}\")\n",
    "        elif weights_path is not None and self.model is not None:\n",
    "            self.model.load_state_dict(torch.load(weights_path, map_location=self.device))\n",
    "            print(f\"Weights loaded from {weights_path}\")\n",
    "        else:\n",
    "            raise ValueError(\"Either model_path or (weights_path and a created model) must be provided\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_losses(self):\n",
    "        return self.train_losses, self.test_losses"
   ],
   "id": "af8b96504353fedd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.110813Z",
     "start_time": "2025-03-17T21:28:52.107880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Inference:\n",
    "    def __init__(self, model=None, device=None):\n",
    "        self.model = model\n",
    "        self.device = device if device is not None else torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else\n",
    "            \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.predictions = None\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not set. Call set_model first.\")\n",
    "\n",
    "        # Move data to device\n",
    "        X_test = X_test.to(self.device)\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Generate predictions\n",
    "        self.predictions = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(X_test)):\n",
    "                input_ = X_test[i].reshape(1, X_test.shape[1], X_test.shape[2])\n",
    "                p = self.model(input_)[0, 0].item()\n",
    "                self.predictions.append(p)\n",
    "\n",
    "        print(f\"Generated {len(self.predictions)} predictions\")\n",
    "        return self.predictions\n",
    "\n",
    "    def get_predictions(self):\n",
    "        return self.predictions"
   ],
   "id": "ab8a77d5ffaed618",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.122625Z",
     "start_time": "2025-03-17T21:28:52.118802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Analysis:\n",
    "    def __init__(self):\n",
    "        self.true_values = None\n",
    "        self.predictions = None\n",
    "        self.metrics = {}\n",
    "\n",
    "    def set_data(self, true_values, predictions):\n",
    "        if isinstance(true_values, torch.Tensor):\n",
    "            self.true_values = true_values.cpu().detach().numpy()\n",
    "        else:\n",
    "            self.true_values = true_values\n",
    "\n",
    "        self.predictions = predictions\n",
    "\n",
    "    def calculate_metrics(self):\n",
    "        if self.true_values is None or self.predictions is None:\n",
    "            raise ValueError(\"Data not set. Call set_data first.\")\n",
    "\n",
    "        # Calculate MAE\n",
    "        self.metrics['MAE'] = mean_absolute_error(self.true_values, self.predictions)\n",
    "\n",
    "        # Calculate MSE\n",
    "        self.metrics['MSE'] = mean_squared_error(self.true_values, self.predictions)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        self.metrics['RMSE'] = np.sqrt(self.metrics['MSE'])\n",
    "\n",
    "        print(f\"Metrics calculated - MAE: {self.metrics['MAE']:.3f}, MSE: {self.metrics['MSE']:.3f}, RMSE: {self.metrics['RMSE']:.3f}\")\n",
    "        return self.metrics\n",
    "\n",
    "    def save_metrics(self, file_path):\n",
    "        if not self.metrics:\n",
    "            raise ValueError(\"Metrics not calculated. Call calculate_metrics first.\")\n",
    "\n",
    "        # Create a DataFrame from the metrics\n",
    "        metrics_df = pd.DataFrame([self.metrics])\n",
    "\n",
    "    def analyze_error_distribution(self):\n",
    "        if self.true_values is None or self.predictions is None:\n",
    "            raise ValueError(\"Data not set. Call set_data first.\")\n",
    "\n",
    "        # Calculate errors\n",
    "        errors = self.true_values.flatten() - np.array(self.predictions)\n",
    "\n",
    "        # Basic statistics of errors\n",
    "        error_stats = {\n",
    "            'mean': np.mean(errors),\n",
    "            'std': np.std(errors),\n",
    "            'min': np.min(errors),\n",
    "            'max': np.max(errors)\n",
    "        }\n",
    "\n",
    "        print(f\"Error statistics - Mean: {error_stats['mean']:.3f}, Std: {error_stats['std']:.3f}, Min: {error_stats['min']:.3f}, Max: {error_stats['max']:.3f}\")\n",
    "        return errors, error_stats\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return self.metrics"
   ],
   "id": "4d9579f3742615db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.132885Z",
     "start_time": "2025-03-17T21:28:52.128368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Display:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.predictions = None\n",
    "        self.dates = None\n",
    "\n",
    "    def set_data(self, original_data, predictions, start_idx=None):\n",
    "        self.data = original_data\n",
    "        self.predictions = predictions\n",
    "\n",
    "        # Prepare the plot DataFrame\n",
    "        plot_len = len(predictions)\n",
    "        if start_idx is None:\n",
    "            start_idx = -plot_len\n",
    "\n",
    "        self.plot_df = original_data[['date', 'mean_temp']].copy(deep=True)\n",
    "        self.plot_df = self.plot_df.iloc[start_idx:]\n",
    "        self.plot_df['prediction'] = predictions\n",
    "        self.plot_df.set_index('date', inplace=True)\n",
    "\n",
    "    def plot_results(self, title=None, figsize=(20, 10)):\n",
    "        if self.plot_df is None:\n",
    "            raise ValueError(\"Data not set. Call set_data first.\")\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(self.plot_df['mean_temp'], label='Actual Temperature', linewidth=1)\n",
    "        plt.plot(self.plot_df['prediction'], label='Predicted Temperature', linewidth=1)\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Temperature (°C)')\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "        if title:\n",
    "            plt.title(title)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_by_year(self, figsize=(20, 10)):\n",
    "        if self.plot_df is None:\n",
    "            raise ValueError(\"Data not set. Call set_data first.\")\n",
    "\n",
    "        # Group data by year\n",
    "        plot_df_by_years = []\n",
    "        for y in self.plot_df.index.year.unique():\n",
    "            plot_df_by_years.append((y, self.plot_df.loc[self.plot_df.index.year == y]))\n",
    "\n",
    "        # Plot each year separately\n",
    "        for year, year_df in plot_df_by_years:\n",
    "            plt.figure(figsize=figsize)\n",
    "            plt.plot(year_df['mean_temp'], label='Actual Temperature', linewidth=1)\n",
    "            plt.plot(year_df['prediction'], label='Predicted Temperature', linewidth=1)\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Temperature (°C)')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.title(f'Temperature in {year}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_error_histogram(self, errors, bins=25, figsize=(12, 8)):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.hist(errors, bins=bins)\n",
    "        plt.xlabel('Temperature Difference (Actual - Predicted)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Distribution of Prediction Errors')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_training_history(self, train_losses, test_losses, figsize=(12, 8)):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(test_losses, label='Test Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training History')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "34543dadb667ec3b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.137222Z",
     "start_time": "2025-03-17T21:28:52.135302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SharedData:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "        # Semaphores for synchronization\n",
    "        self.preprocess_train_empty = threading.Semaphore(1)  # Initially empty for training data\n",
    "        self.preprocess_train_full = threading.Semaphore(0)   # Initially no data available\n",
    "\n",
    "        self.train_infer_empty = threading.Semaphore(1)       # Initially empty for model\n",
    "        self.train_infer_full = threading.Semaphore(0)        # Initially no model available\n",
    "\n",
    "        self.infer_analysis_empty = threading.Semaphore(1)    # Initially empty for predictions\n",
    "        self.infer_analysis_full = threading.Semaphore(0)     # Initially no predictions available\n",
    "\n",
    "        self.analysis_display_empty = threading.Semaphore(1)  # Initially empty for metrics\n",
    "        self.analysis_display_full = threading.Semaphore(0)   # Initially no metrics available\n",
    "\n",
    "        # Mutex for shared data access\n",
    "        self.mutex = threading.Semaphore(1)"
   ],
   "id": "2861709752b02ae1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:28:52.151438Z",
     "start_time": "2025-03-17T21:28:52.143969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_task(shared_data, file_path):\n",
    "    print(\"Starting preprocessing task...\")\n",
    "\n",
    "    # Create preprocessing object\n",
    "    preprocessor = Preprocessing(file_path)\n",
    "\n",
    "    # Load and clean data\n",
    "    preprocessor.load_data()\n",
    "    preprocessor.clean_data()\n",
    "\n",
    "    # Prepare data for model\n",
    "    X_train, y_train, X_test, y_test = preprocessor.prepare_data_for_model(target_column='mean_temp')\n",
    "\n",
    "    # Store data in shared object\n",
    "    shared_data.preprocess_train_empty.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    shared_data.data['X_train'] = X_train\n",
    "    shared_data.data['y_train'] = y_train\n",
    "    shared_data.data['X_test'] = X_test\n",
    "    shared_data.data['y_test'] = y_test\n",
    "    shared_data.data['preprocessor'] = preprocessor\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.preprocess_train_full.release()\n",
    "\n",
    "    print(\"Preprocessing task completed.\")\n",
    "\n",
    "def train_task(shared_data, epochs=200):\n",
    "    print(\"Waiting for preprocessing to complete...\")\n",
    "\n",
    "    # Wait for preprocessing to complete\n",
    "    shared_data.preprocess_train_full.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    # Get data from shared object\n",
    "    X_train = shared_data.data['X_train']\n",
    "    y_train = shared_data.data['y_train']\n",
    "    X_test = shared_data.data['X_test']\n",
    "    y_test = shared_data.data['y_test']\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.preprocess_train_empty.release()\n",
    "\n",
    "    print(\"Starting training task...\")\n",
    "\n",
    "    # Create and train model\n",
    "    trainer = Training()\n",
    "    input_dim = X_train.shape[2]  # Number of features\n",
    "    trainer.create_model(input_dim=input_dim)\n",
    "\n",
    "    train_losses, test_losses = trainer.train_model(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        learning_rate=0.01,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    trainer.save_model('lstm_model.pt', 'lstm_weights.pt')\n",
    "\n",
    "    # Store model in shared object\n",
    "    shared_data.train_infer_empty.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    shared_data.data['model'] = trainer.get_model()\n",
    "    shared_data.data['train_losses'] = train_losses\n",
    "    shared_data.data['test_losses'] = test_losses\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.train_infer_full.release()\n",
    "\n",
    "    print(\"Training task completed.\")\n",
    "\n",
    "def infer_task(shared_data):\n",
    "    print(\"Waiting for training to complete...\")\n",
    "\n",
    "    # Wait for training to complete\n",
    "    shared_data.train_infer_full.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    # Get model and test data from shared object\n",
    "    model = shared_data.data['model']\n",
    "    X_test = shared_data.data['X_test']\n",
    "    y_test = shared_data.data['y_test']\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.train_infer_empty.release()\n",
    "\n",
    "    print(\"Starting inference task...\")\n",
    "\n",
    "    # Create inference object and generate predictions\n",
    "    inference = Inference()\n",
    "    inference.set_model(model)\n",
    "    predictions = inference.predict(X_test)\n",
    "\n",
    "    # Store predictions in shared object\n",
    "    shared_data.infer_analysis_empty.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    shared_data.data['predictions'] = predictions\n",
    "    shared_data.data['true_values'] = y_test\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.infer_analysis_full.release()\n",
    "\n",
    "    print(\"Inference task completed.\")\n",
    "\n",
    "def analysis_task(shared_data):\n",
    "    print(\"Waiting for inference to complete...\")\n",
    "\n",
    "    # Wait for inference to complete\n",
    "    shared_data.infer_analysis_full.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    # Get predictions and true values from shared object\n",
    "    predictions = shared_data.data['predictions']\n",
    "    true_values = shared_data.data['true_values']\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.infer_analysis_empty.release()\n",
    "\n",
    "    print(\"Starting analysis task...\")\n",
    "\n",
    "    # Create analysis object and calculate metrics\n",
    "    analyzer = Analysis()\n",
    "    analyzer.set_data(true_values, predictions)\n",
    "    metrics = analyzer.calculate_metrics()\n",
    "\n",
    "    # Analyze error distribution\n",
    "    errors, error_stats = analyzer.analyze_error_distribution()\n",
    "\n",
    "    # Store metrics and errors in shared object\n",
    "    shared_data.analysis_display_empty.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    shared_data.data['metrics'] = metrics\n",
    "    shared_data.data['errors'] = errors\n",
    "    shared_data.data['error_stats'] = error_stats\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.analysis_display_full.release()\n",
    "\n",
    "    print(\"Analysis task completed.\")\n",
    "\n",
    "def display_task(shared_data):\n",
    "    print(\"Waiting for analysis to complete...\")\n",
    "\n",
    "    # Wait for analysis to complete\n",
    "    shared_data.analysis_display_full.acquire()\n",
    "    shared_data.mutex.acquire()\n",
    "\n",
    "    # Get data from shared object\n",
    "    metrics = shared_data.data['metrics']\n",
    "    errors = shared_data.data['errors']\n",
    "    predictions = shared_data.data['predictions']\n",
    "    preprocessor = shared_data.data['preprocessor']\n",
    "    train_losses = shared_data.data['train_losses']\n",
    "    test_losses = shared_data.data['test_losses']\n",
    "\n",
    "    shared_data.mutex.release()\n",
    "    shared_data.analysis_display_empty.release()\n",
    "\n",
    "    print(\"Starting display task...\")\n",
    "\n",
    "    # Get original data from preprocessor\n",
    "    original_data = preprocessor.get_original_data()\n",
    "\n",
    "    # Create display object and set data\n",
    "    displayer = Display()\n",
    "    displayer.set_data(original_data, predictions)\n",
    "\n",
    "    # Plot results\n",
    "    displayer.plot_results(title='LSTM Temperature Forecast')\n",
    "\n",
    "    # Plot by year\n",
    "    displayer.plot_by_year()\n",
    "\n",
    "    # Plot error histogram\n",
    "    displayer.plot_error_histogram(errors)\n",
    "\n",
    "    # Plot training history\n",
    "    displayer.plot_training_history(train_losses, test_losses)\n",
    "\n",
    "    print(\"Display task completed.\")\n",
    "\n",
    "    # Print summary of metrics\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "def run_pipeline(file_path, epochs=200):\n",
    "    # Create shared data object\n",
    "    shared_data = SharedData()\n",
    "\n",
    "    # Create threads\n",
    "    preprocess_thread = threading.Thread(target=preprocess_task, args=(shared_data, file_path))\n",
    "    train_thread = threading.Thread(target=train_task, args=(shared_data, epochs))\n",
    "    infer_thread = threading.Thread(target=infer_task, args=(shared_data,))\n",
    "    analysis_thread = threading.Thread(target=analysis_task, args=(shared_data,))\n",
    "    display_thread = threading.Thread(target=display_task, args=(shared_data,))\n",
    "\n",
    "    # Start threads\n",
    "    start_time = time.time()\n",
    "\n",
    "    preprocess_thread.start()\n",
    "    train_thread.start()\n",
    "    infer_thread.start()\n",
    "    analysis_thread.start()\n",
    "    display_thread.start()\n",
    "\n",
    "    # Wait for all threads to complete\n",
    "    preprocess_thread.join()\n",
    "    train_thread.join()\n",
    "    infer_thread.join()\n",
    "    analysis_thread.join()\n",
    "    display_thread.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Print execution time\n",
    "    print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
   ],
   "id": "a86cf2a7980effe2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T21:29:56.819513Z",
     "start_time": "2025-03-17T21:28:52.154212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the pipeline\n",
    "    run_pipeline('London_Weather.csv', epochs=200)"
   ],
   "id": "b2ee33fb609606dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing task...\n",
      "Waiting for preprocessing to complete...\n",
      "Waiting for training to complete...\n",
      "Waiting for inference to complete...\n",
      "Waiting for analysis to complete...\n",
      "Data loaded with shape: (15341, 10)\n",
      "Data cleaned. New shape: (15261, 10)\n",
      "Data prepared for model -> X_train shape: torch.Size([12208, 20, 9]), y_train shape: torch.Size([12208, 1])\n",
      "Preprocessing task completed.\n",
      "Starting training task...\n",
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (train_task):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/0b/tynds1f1557gyf7jj3cn07jc0000gn/T/ipykernel_59985/2036808291.py\", line 52, in train_task\n",
      "  File \"/var/folders/0b/tynds1f1557gyf7jj3cn07jc0000gn/T/ipykernel_59985/2835125935.py\", line 39, in train_model\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/0b/tynds1f1557gyf7jj3cn07jc0000gn/T/ipykernel_59985/3365982949.py\", line 27, in forward\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: MPS backend out of memory (MPS allocated: 6.71 GB, other allocations: 7.46 GB, max allowed: 9.07 GB). Tried to allocate 47.75 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# Run the pipeline\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mrun_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLondon_Weather.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[9], line 214\u001B[0m, in \u001B[0;36mrun_pipeline\u001B[0;34m(file_path, epochs)\u001B[0m\n\u001B[1;32m    212\u001B[0m preprocess_thread\u001B[38;5;241m.\u001B[39mjoin()\n\u001B[1;32m    213\u001B[0m train_thread\u001B[38;5;241m.\u001B[39mjoin()\n\u001B[0;32m--> 214\u001B[0m \u001B[43minfer_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m analysis_thread\u001B[38;5;241m.\u001B[39mjoin()\n\u001B[1;32m    216\u001B[0m display_thread\u001B[38;5;241m.\u001B[39mjoin()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:1147\u001B[0m, in \u001B[0;36mThread.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[1;32m   1150\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[1;32m   1151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:1167\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1168\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
